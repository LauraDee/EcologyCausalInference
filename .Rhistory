install.packages('rmarkdown')
install.packages("knitr")
[Assignments](https://LauraDee.github.io/EcologyCausalInference/assignments.html#final-project-option-1-data-analysis-project) tab for descriptions of the requirements for the write-up)
## May 1 is last day of class - Projects Due Friday May 2
Final project write-ups due (see [Assignments](https://LauraDee.github.io/EcologyCausalInference/assignments.html#final-project-option-1-data-analysis-project) tab for descriptions of the requirements for the write-up)
project:
type: website
library(quartets)
library(datasauRus)
install.package('library(datasauRus)')
install.package('datasauRus')
install.packages('datasauRus')
n <- 1000000
tibble(
roll_1 = sample(1:6, n, replace = TRUE),
roll_2 = sample(1:6, n, replace = TRUE),
) |>
reframe(roll_1 + roll_2 == 2) |>
pull() |>
sum() / n
install.packages('quartets')
f
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tidysynth)
library(nlme)
library(AICcmodavg)
library(purrr)
library(ggpubr)
library(microsynth)
library(fixest)
setwd("~/Downloads/")
city.data <- read.csv("cities.scm.input.csv")
city.data <- city.data %>%
rename("nobs45km" = "n.obs45km")
#Subset for cities with closer number of observations during treatment year
cities.pool <- city.data %>%
filter(year == 2021) %>%
filter(nobs45km > 75 & nobs45km < 500)
#Extract the city column
cities.pool <-cities.pool$City
#Keeping subset of cities in final dataframe
#Removing Boston, Atlanta and Baltimore for experiencing this treatment. Removing Houston for abnormal abundance spike in 2016.
city.data <- city.data %>%
filter(City != "Boston"& City != "Atlanta" & City != "Baltimore" & City != "Houston")%>%
filter(City %in% cities.pool)
write.csv(city.data, "city_dat.csv", row.names = FALSE)
# try in scpi
library(scpi)
library(data.table)
donor.cities <- unique(city.data$City)
donor.cities <- donor.cities[!(donor.cities == "Philadelphia")]
city.data$Temp <-scale(city.data$Temp)
city.data$Prec <- scale(city.data$Prec)
city.data$imperv45km <- scale(city.data$imperv45km)
city.data$Population <- scale(city.data$Population)
feature.vars <- c("Temp","Prec","imperv45km","Population","nobs45km","tcc45km")
city.data <- city.data %>%
rename(unit.no = ID)
dat <- scdata(df = city.data,
id.var = "City",
time.var = "year",
outcome.var = "nobs45km",
period.pre = (2015:2021),
period.post = (2022),
unit.tr = "Philadelphia",
unit.co = donor.cities,
features = feature.vars,
cov.adj = list('Temp' = c("constant"),
'Prec' = c("constant"),
'imperv45km' = c("constant"),
'Population' = c("trend"),
'nobs45km' = c("trend"),
'tcc45km' = c("constant")))
summary(dat)
est.si  <- scest(data = dat)
city.data.cors <- city.data |>
select("Temp","Prec","tcc45km","imperv45km","Population","nobs45km")
cor(city.data.cors)
#Estimating uncertainty
sims <- 1000
u.order <- 1
u.lags <- 0
u.sigma <- "HC1"
u.missp <- TRUE
e.order <- 1
e.lags <- 0
e.method <- "gaussian"
lgapp <- "linear"
cores <- 1
set.seed(0)
res.pi <- scpi(data = dat, sims = sims, e.method = e.method, e.order = e.order, e.lags = e.lags, u.order = u.order, u.lags = u.lags, u.sigma = u.sigma, u.missp = u.missp, cores = cores, w.constr = list(name = "simplex"))
scplot(res.pi, e.out = TRUE)
```
Asia_Theme <- theme(
plot.title = element_text(size = 20),
plot.caption = element_text(size = 16),
axis.title = element_text(size = 20),
axis.text = element_text(size = 20),
axis.text.x = element_text(size = 20),
legend.text = element_text(size= 20))
trendplot <- gbifcity_out %>% plot_trends()+
Asia_Theme +
labs(title = "Synthetic Control Method", caption = NULL,
x = "Year",
y = "Bee observations")+
ylim(0,425)+
xlim(2015,2022)+
theme(legend.position = "none")
city.data.ba <- city.data %>%
mutate(Treated = ifelse(year >= 2021 & City == "Philadelphia", 1, 0))
ba.model <- feols(nobs45km ~ Treated, data = city.data.ba, cluster = ~City)
summary(ba.model)
confint.ba <- confint(ba.model)
confint.ba
ba.model <- feols(nobs45km ~ Treated, data = city.data.ba, cluster = "City")
summary(ba.model)
#add city as a fixed effect too
ba.model_ld <- feols(nobs45km ~ Treated | City, data = city.data.ba, cluster = "City")
summary(ba.model_ld)
vcov_ba.model_ld <- vcov(ba.model_ld, cluster = "City")
confint.ba
summary(ba.model)
confint.ba <- confint(ba.model)
knitr::opts_chunk$set(echo = TRUE)
ba.model <- feols(nobs45km ~ Treated, data = city.data.ba, cluster = ~City)
summary(ba.model)
confint.ba <- confint(ba.model)
confint.ba
city.data.baci <- city.data %>%
mutate(Time = ifelse(year >= 2021, 1, 0)) %>%
mutate(Treated = if_else(City == "Philadelphia",1,0))%>%
filter(City == "Philadelphia" | City == "Detroit")%>%
filter(year <= 2022)
#Running the Before- After Control Impact model
baci.model <- feols(nobs45km ~ Treated * Time, data = city.data.baci, cluster = ~City)
summary(baci.model)
baci.model <- feols(nobs45km ~ Treated * Time, data = city.data.baci)
summary(baci.model)
confint.baci <- confint(baci.model)
library(tidyr)
library(dplyr)
setwd("/Users/lade8828/Library/CloudStorage/OneDrive-UCB-O365/Documents/GitHub/BCCAch7/data")
docs <- read.csv("reshaped_3_byFlow.csv")
doc2 <- docs %>% filter(Citation != "Chen, 2011, Journal of Sustainable Development",
Citation != "Nielsen, 2015, Global Change Biology",
Citation != "Vaddey, 2010, Watershed Management",
Citation != "Perry, 2007, Climate Change 2007")
list_to_recode <- c("Jenkins et al., 2013, Advances in Parasitology",
"Noyes, 2009, Environment International",
"Dube et al., 2012, INTEGRATED ENVIRONMENTAL ASSESSMENT AND MANAGEMENT",
"Covich et al., 1997, Hydrological Processes")
phys <-  read.csv("./data_cleaning/physicalFlowSubtype_lookup_Feb112025.csv")
biotic <- read.csv("./data_cleaning/bioticFlowSubtype_lookup.csv")
socio <- read.csv("./data_cleaning/socioculturalFlowSubtype_lookup.csv")
phys <-  read.csv("./data_cleaning/physicalFlowSubtype_lookup_Feb112025.csv")
# in the look up files, probably need to first remove the ones removed in the 004 step to avoid confusion
phys <- phys %>% filter(Citation != "Chen, 2011, Journal of Sustainable Development",
Citation != "Nielsen, 2015, Global Change Biology",
Citation != "Vaddey, 2010, Watershed Management",
Citation != "Jenkins et al., 2013, Advances in Parasitology",
Citation != "Dube et al., 2012, INTEGRATED ENVIRONMENTAL ASSESSMENT AND MANAGEMENT", #Mabel checking
Citation != "Covich et al., 1997, Hydrological Processes",
Citation != "de la Fontaine,  2018, Ecology",
Citation != "Perry, 2007, Climate Change 2007")
biotic <- biotic %>% filter(Citation != "Noyes, 2009, Environment International",
Citation != "de la Fontaine,  2018, Ecology",
Citation != "Perry, 2007, Climate Change 2007")
socio <- socio %>% filter(Citation != "Shin et al., 2021, Global Change Biology")
subflows <- rbind(biotic, phys)
#combine subflows look ups into a single datafile - **this didnt work**
subflows <- rbind(biotic, phys)
library(tidyr)
library(dplyr)
library(data.table)
setwd("/Users/lade8828/Library/CloudStorage/OneDrive-UCB-O365/Documents/GitHub/BCCAch7/data")
docs <- read.csv("cleaned_4_byFlow.csv")
#load look up tables
#need to figure out what to do with the FLOW itself that have been changed
biotic <- read.csv("./data_cleaning/bioticFlowSubtype_lookup.csv")
socio <- read.csv("./data_cleaning/socioculturalFlowSubtype_lookup.csv")
phys <-  read.csv("./data_cleaning/physicalFlowSubtype_lookup_Feb112025.csv")
#combine subflows look ups into a single datafile - **this didnt work**
subflows <- rbind(biotic, phys)
#load look up tables
#need to figure out what to do with the FLOW itself that have been changed
biotic <- read.csv("./data_cleaning/bioticFlowSubtype_lookup.csv")
phys <-  read.csv("./data_cleaning/physicalFlowSubtype_lookup_Feb112025.csv")
#combine subflows look ups into a single datafile - **this didnt work**
subflows <- rbind(biotic, phys)
subflows <- rbind(socio, biotic)
identical(names(biotic), names(phys))
glimpse(biotic)
glimpse(phys)
#need to figure out what to do with the FLOW itself that have been changed
biotic <- read.csv("./data_cleaning/bioticFlowSubtype_lookup.csv")
socio <- read.csv("./data_cleaning/socioculturalFlowSubtype_lookup.csv")
phys <-  read.csv("./data_cleaning/physicalFlowSubtype_lookup_Feb112025.csv")
#combine subflows look ups into a single datafile - **this didnt work**
identical(names(biotic), names(phys))
phys <-  read.csv("./data_cleaning/physicalFlowSubtype_lookup_Feb112025.csv")
#combine subflows look ups into a single datafile - **this didnt work**
identical(names(biotic), names(phys))
glimpse(phys)
glimpse(biotic)
#need to figure out what to do with the FLOW itself that have been changed
biotic <- read.csv("./data_cleaning/bioticFlowSubtype_lookup.csv")
socio <- read.csv("./data_cleaning/socioculturalFlowSubtype_lookup.csv")
phys <-  read.csv("./data_cleaning/physicalFlowSubtype_lookup_Feb112025.csv")
#combine subflows look ups into a single datafile - **this didnt work**
identical(names(biotic), names(phys))
glimpse(biotic)
phys <-  read.csv("./data_cleaning/physicalFlowSubtype_lookup.csv")
#combine subflows look ups into a single datafile - **this didnt work**
identical(names(biotic), names(phys))
#load look up tables
#need to figure out what to do with the FLOW itself that have been changed
biotic <- read.csv("./data_cleaning/bioticFlowSubtype_lookup.csv")
biotic <- read.csv("./data_cleaning/bioticFlowSubtype_lookup.csv")
socio <- read.csv("./data_cleaning/socioculturalFlowSubtype_lookup.csv")
phys <-  read.csv("./data_cleaning/physicalFlowSubtype_lookup.csv")
subflows <- rbind(biotic, phys)
biotic <- read.csv("./data_cleaning/bioticFlowSubtype_lookup.csv")
socio <- read.csv("./data_cleaning/socioculturalFlowSubtype_lookup.csv")
phys <-  read.csv("./data_cleaning/physicalFlowSubtype_lookup.csv")
identical(names(biotic), names(socio))
rm(list = ls())
# ****TO DO STIL BEFORE THIS STEP -- #need to figure out what to do with the FLOW itself that have been changed***
library(tidyr)
library(dplyr)
library(data.table)
setwd("/Users/lade8828/Library/CloudStorage/OneDrive-UCB-O365/Documents/GitHub/BCCAch7/data")
docs <- read.csv("cleaned_4_byFlow.csv")
#need to figure out what to do with the FLOW itself that have been changed
biotic <- read.csv("./data_cleaning/bioticFlowSubtype_lookup.csv")
socio <- read.csv("./data_cleaning/socioculturalFlowSubtype_lookup.csv")
phys <-  read.csv("./data_cleaning/physicalFlowSubtype_lookup.csv")
identical(names(biotic), names(phys))
identical(names(biotic), names(socio))
glimpse(socio)
glimpse(biotic)
glimpse(phys)
updated_docs <- merge(subflows, docs, by = "ID_DOI_by_Flow", all.y = T)
subflows <- rbind(biotic, phys)
names(phys) <- names(biotic)
#combine subflows look ups into a single datafile - **this didnt work**
identical(names(biotic), names(phys))
subflows <- rbind(biotic, phys)
subflows <- subflows %>% filter(Citation != "Chen, 2011, Journal of Sustainable Development",
Citation != "Nielsen, 2015, Global Change Biology",
Citation != "Vaddey, 2010, Watershed Management",
Citation != "Jenkins et al., 2013, Advances in Parasitology", #Enrique recoding
Citation != "Dube et al., 2012, INTEGRATED ENVIRONMENTAL ASSESSMENT AND MANAGEMENT", #Mabel checking
Citation != "Covich et al., 1997, Hydrological Processes", #Mabel recoding
Citation != "de la Fontaine,  2018, Ecology", #Colleen recoded
Citation != "Noyes, 2009, Environment International", #Becky recoding
Citation != "Perry, 2007, Climate Change 2007",
Citation != "Shin et al., 2021, Global Change Biology") #Kyle recoded
updated_docs <- merge(subflows, docs, by = "ID_DOI_by_Flow", all.y = T)
glimpse(updated_docs)
#clean entries so all of the range shifts are written the same
updated_docs[X2.2.Subtype.NEW == "range shifts", X2.2.Subtype.NEW := "Range shift"]
#clean entries so all of the range shifts are written the same
updated_docs[X2.2.Subtype.NEW == "'range shifts'", X2.2.Subtype.NEW := "'Range shift'"]
---
title: "IPTW"
